{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:- Crawling web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser  \n",
    "from urllib.request import urlopen  \n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re, math\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "class LinkParser(HTMLParser):\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'a':\n",
    "            for (key, value) in attrs:\n",
    "                if key == 'href':\n",
    "                    newUrl = parse.urljoin(self.baseUrl, value)\n",
    "                    self.links = self.links + [newUrl]\n",
    "\n",
    "    def getLinks(self, url):\n",
    "        self.links = []\n",
    "        self.baseUrl = url\n",
    "        response = urlopen(url)\n",
    "        if response.getheader('Content-Type')=='text/html':\n",
    "            htmlBytes = response.read()\n",
    "            htmlString = htmlBytes.decode(\"utf-8\")\n",
    "            self.feed(htmlString)\n",
    "            return htmlString, self.links\n",
    "        else:\n",
    "            return \"\",[]\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "cosine_vals = []\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "     intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "     numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "     sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "     sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "     if not denominator:\n",
    "        return 0.0\n",
    "     else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "     words = WORD.findall(text)\n",
    "     return Counter(words)\n",
    " \n",
    "    \n",
    "    \n",
    "def spider(url, maxPages):\n",
    "    pagesToVisit = [url]\n",
    "    numberVisited = 0\n",
    "    print(url)\n",
    "    print(maxPages)\n",
    "    \n",
    "    query = \"We make sure website fast , secure & always -so visitors & search engines trust\"\n",
    "    while numberVisited < maxPages and pagesToVisit != []:# and not foundWord:\n",
    "        numberVisited = numberVisited + 1\n",
    "        url = pagesToVisit[0]\n",
    "        pagesToVisit = pagesToVisit[1:]\n",
    "        \n",
    "        print(str(numberVisited) + \". Visiting:\", url)\n",
    "        parser = LinkParser()\n",
    "        data, links = parser.getLinks(url)\n",
    "        web_data = BeautifulSoup(data,'lxml')    \n",
    "        \n",
    "        complete_text = \"\"\n",
    "        for para in web_data.find_all('p'):\n",
    "            complete_text = complete_text + para.text\n",
    "        \n",
    "        pagesToVisit = pagesToVisit + links\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(complete_text)\n",
    "        \n",
    "        filtered_sentence = []\n",
    "        \n",
    "        for w in word_tokens:\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        \n",
    "        filename = \"File \" + str(numberVisited) + \".txt\"\n",
    "        f = open(filename, \"w+\")\n",
    "        f.write(\" \".join(str(x) for x in filtered_sentence))\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        vector1 = text_to_vector(query)\n",
    "        vector2 = text_to_vector(\" \".join(str(x) for x in filtered_sentence))\n",
    "        \n",
    "        cosine = get_cosine(vector1, vector2)\n",
    "        \n",
    "        print('Cosine:', cosine)\n",
    "        \n",
    "        cosine_vals.append([cosine, url])\n",
    "\n",
    "def print_cosine():\n",
    "    print(cosine_vals)\n",
    "\n",
    "def print_decreasing():\n",
    "    cosine_vals.sort(reverse = True)\n",
    "    \n",
    "    for url in cosine_vals:\n",
    "        print(url[1])        \n",
    "        \n",
    "def calculate_similarity(maxPages, query):\n",
    "    # Bring in standard stopwords\n",
    "    stopWords = stopwords.words('english')\n",
    "    \n",
    "    print (\"\\nCalculating document similarity scores...\")\n",
    "\n",
    "    train_set = [query]\n",
    "    for i in range(maxPages):\n",
    "        # Open and read a bunch of files \n",
    "        f = open('File ' + str(i+1) + '.txt')\n",
    "        doc = str(f.read())\n",
    "        train_set.append(doc)\n",
    "\n",
    "    # Set up the vectoriser, passing in the stop words\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stopWords)\n",
    "    \n",
    "    # Apply the vectoriser to the training set\n",
    "    tfidf_matrix_train = tfidf_vectorizer.fit_transform(train_set)\n",
    "    \n",
    "    # Print the score\n",
    "    print (\"\\nSimilarity Score [*] \",cosine_similarity(tfidf_matrix_train[0:1], tfidf_matrix_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.dreamhost.com\n",
      "5\n",
      "1. Visiting: http://www.dreamhost.com\n",
      "Cosine: 0.2050282630438012\n",
      "2. Visiting: https://www.dreamhost.com/domains/club/\n",
      "Cosine: 0.04705270219194202\n",
      "3. Visiting: http://www.dreamhost.com\n",
      "Cosine: 0.2050282630438012\n",
      "4. Visiting: http://www.dreamhost.com/wordpress/\n",
      "Cosine: 0.08421519210665192\n",
      "5. Visiting: http://www.dreamhost.com/wordpress/\n",
      "Cosine: 0.08421519210665192\n"
     ]
    }
   ],
   "source": [
    "#spider(\"url\", maxPages)\n",
    "spider(\"http://www.dreamhost.com\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:- DIFFERENT CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure\n",
      "belles_lettres\n",
      "editorial\n",
      "fiction\n",
      "government\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(brown.categories()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'was', 'among', 'these', 'that', 'Hinkle', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='humor') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'was',\n",
       " 'among',\n",
       " 'these',\n",
       " 'that',\n",
       " 'Hinkle',\n",
       " 'identified',\n",
       " 'a',\n",
       " 'photograph',\n",
       " 'of',\n",
       " 'Barco',\n",
       " '!',\n",
       " '!',\n",
       " 'For',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'Barco',\n",
       " ',',\n",
       " 'fancying']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories='humor') [:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dan',\n",
       " 'Morgan',\n",
       " 'told',\n",
       " 'himself',\n",
       " 'he',\n",
       " 'would',\n",
       " 'forget',\n",
       " 'Ann',\n",
       " 'Turner',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'well',\n",
       " 'rid',\n",
       " 'of',\n",
       " 'her',\n",
       " '.',\n",
       " 'He',\n",
       " 'certainly',\n",
       " \"didn't\",\n",
       " 'want',\n",
       " 'a',\n",
       " 'wife',\n",
       " 'who',\n",
       " 'was',\n",
       " 'fickle',\n",
       " 'as',\n",
       " 'Ann',\n",
       " '.',\n",
       " 'If',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " ',',\n",
       " \"he'd\",\n",
       " 'have',\n",
       " 'been',\n",
       " 'asking',\n",
       " 'for',\n",
       " 'trouble',\n",
       " '.',\n",
       " 'But',\n",
       " 'all',\n",
       " 'of',\n",
       " 'this',\n",
       " 'was',\n",
       " 'rationalization',\n",
       " '.',\n",
       " 'Sometimes',\n",
       " 'he',\n",
       " 'woke',\n",
       " 'up',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " 'of',\n",
       " 'the',\n",
       " 'night',\n",
       " 'thinking',\n",
       " 'of',\n",
       " 'Ann',\n",
       " ',',\n",
       " 'and',\n",
       " 'then',\n",
       " 'could',\n",
       " 'not',\n",
       " 'get',\n",
       " 'back',\n",
       " 'to',\n",
       " 'sleep',\n",
       " '.',\n",
       " 'His',\n",
       " 'plans',\n",
       " 'and',\n",
       " 'dreams',\n",
       " 'had',\n",
       " 'revolved',\n",
       " 'around',\n",
       " 'her']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories = 'adventure')[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'fellow',\n",
       " 'citizens',\n",
       " ':',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'here',\n",
       " 'today',\n",
       " 'humbled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'task',\n",
       " 'before',\n",
       " 'us',\n",
       " ',',\n",
       " 'grateful',\n",
       " 'for',\n",
       " 'the',\n",
       " 'trust',\n",
       " 'you']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids='2009-Obama.txt')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My fellow citizens : I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors . I thank President Bush for his service to our nation , as well as the generosity and cooperation he has shown throughout this transition . Forty - four Americans have now taken the presidential oath . The words have been spoken during rising tides of prosperity and the still waters of peace . Yet , every so often the oath is taken amidst gathering clouds and raging storms \n"
     ]
    }
   ],
   "source": [
    "a = \"\"\n",
    "for i in range(100): \n",
    "    a = a + inaugural.words(fileids = '2009-Obama.txt')[i] + \" \"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('german')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jieba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-71874e60dc26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mjieba\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jieba'"
     ]
    }
   ],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jieba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0c8af729cf8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjieba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'医生或科学家检测用的'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jieba' is not defined"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut('医生或科学家检测用的', cut_all=True)\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries=nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "(\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "(\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[10000:10015]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\UTKARSH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "labeled_names=([(name,'male') for name in names.words('male.txt')]+[(name,'female') for name in names.words('female.txt')])\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('Rosina', 'female'),\n",
       "  ('Siana', 'female'),\n",
       "  ('Bartlett', 'male'),\n",
       "  ('Trace', 'female'),\n",
       "  ('Philomena', 'female'),\n",
       "  ('Emmeline', 'female'),\n",
       "  ('Brit', 'female'),\n",
       "  ('Suzy', 'female'),\n",
       "  ('Sheelagh', 'female'),\n",
       "  ('Laureen', 'female')],)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_names[:10],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tera', 'female'),\n",
       " ('Geo', 'male'),\n",
       " ('Fae', 'female'),\n",
       " ('Merla', 'female'),\n",
       " ('Shayla', 'female'),\n",
       " ('Ignacius', 'male'),\n",
       " ('Shari', 'female'),\n",
       " ('Beatrisa', 'female'),\n",
       " ('Nicolette', 'female'),\n",
       " ('Stern', 'male')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " labeled_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:- Stemmers, Tokenizers and Lemmatizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmerporter = PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appl'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utkarsh'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('utkarsh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('programming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harass'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('harass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('sing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utkarshni'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('utkarshnies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utkarsh'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('utkarshes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utkarsh'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('utkarshing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ant'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('ants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cup'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('cups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cupper'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('cupper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cupe'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('cupes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bush'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('bushes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coupl'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('couples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ash'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('ashes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'danc'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('dances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manag'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('manages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cue'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('cues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('computing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerporter.stem('computers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a country like India, where a mass of population lives in the villages, there are times when parents have work to take care of and cannot keep an eye on their children all day round. In many cases, when even the females in houses have to go to work, but cannot always carry their children along with them, they have no other choice but to leave them back at their homes. Due to these reasons and more, there has been a rapid increase in security risks of children recently. The current statistics report around 174 child missing cases on an everyday basis and about 505 are still not found in India. Is there a way to improve this situation? Is there any way by which parents can keep a track on their child even while not being around? Our project mainly aims at helping these parents out, so we propose a smart child tracking wearable system which helps them to keep track of the live location of the child at any given time. This system is implemented as a wearable band-like device which when wore by the child, helps in locating it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [stemmerporter.stem(token) for token in text.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a countri like india, where a mass of popul live in the villages, there are time when parent have work to take care of and cannot keep an eye on their children all day round. In mani cases, when even the femal in hous have to go to work, but cannot alway carri their children along with them, they have no other choic but to leav them back at their homes. due to these reason and more, there ha been a rapid increas in secur risk of children recently. the current statist report around 174 child miss case on an everyday basi and about 505 are still not found in india. Is there a way to improv thi situation? Is there ani way by which parent can keep a track on their child even while not be around? our project mainli aim at help these parent out, so we propos a smart child track wearabl system which help them to keep track of the live locat of the child at ani given time. thi system is implement as a wearabl band-lik devic which when wore by the child, help in locat it.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a country like India, where a mass of population life in the villages, there are time when parent have work to take care of and cannot keep an eye on their child all day round. In many cases, when even the female in house have to go to work, but cannot always carry their child along with them, they have no other choice but to leave them back at their homes. Due to these reason and more, there ha been a rapid increase in security risk of child recently. The current statistic report around 174 child missing case on an everyday basis and about 505 are still not found in India. Is there a way to improve this situation? Is there any way by which parent can keep a track on their child even while not being around? Our project mainly aim at helping these parent out, so we propose a smart child tracking wearable system which help them to keep track of the live location of the child at any given time. This system is implemented a a wearable band-like device which when wore by the child, help in locating it.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"In a country like India, where a mass of population lives in the villages, there are times when parents have work to take care of and cannot keep an eye on their children all day round. In many cases, when even the females in houses have to go to work, but cannot always carry their children along with them, they have no other choice but to leave them back at their homes. Due to these reasons and more, there has been a rapid increase in security risks of children recently. The current statistics report around 174 child missing cases on an everyday basis and about 505 are still not found in India. Is there a way to improve this situation? Is there any way by which parents can keep a track on their child even while not being around? Our project mainly aims at helping these parents out, so we propose a smart child tracking wearable system which helps them to keep track of the live location of the child at any given time. This system is implemented as a wearable band-like device which when wore by the child, helps in locating it.\"\n",
    "text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better', pos = 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a country like India, where a mass of population life in the villages, there are time when parent have work to take care of and cannot keep an eye on their child all day round. In many cases, when even the female in house have to go to work, but cannot always carry their child along with them, they have no other choice but to leave them back at their homes. Due to these reason and more, there ha been a rapid increase in security risk of child recently. The current statistic report around 174 child missing case on an everyday basis and about 505 are still not found in India. Is there a way to improve this situation? Is there any way by which parent can keep a track on their child even while not being around? Our project mainly aim at helping these parent out, so we propose a smart child tracking wearable system which help them to keep track of the live location of the child at any given time. This system is implemented a a wearable band-like device which when wore by the child, help in locating it.\n"
     ]
    }
   ],
   "source": [
    "text = \"In a country like India, where a mass of population lives in the villages, there are times when parents have work to take care of and cannot keep an eye on their children all day round. In many cases, when even the females in houses have to go to work, but cannot always carry their children along with them, they have no other choice but to leave them back at their homes. Due to these reasons and more, there has been a rapid increase in security risks of children recently. The current statistics report around 174 child missing cases on an everyday basis and about 505 are still not found in India. Is there a way to improve this situation? Is there any way by which parents can keep a track on their child even while not being around? Our project mainly aims at helping these parents out, so we propose a smart child tracking wearable system which helps them to keep track of the live location of the child at any given time. This system is implemented as a wearable band-like device which when wore by the child, helps in locating it.\"\n",
    "text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "text = \" \".join(text)\n",
    "print(lemmatizer.lemmatize(text, pos = 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mouse'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"mice\"\n",
    "text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appl'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'manag'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('manages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('sing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cling'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('cling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('singing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cling'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('clinging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shingl'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('shingling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ash'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('ashes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shuffl'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('shuffles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cue'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('cues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dumbl'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('dumbles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queue'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('queues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rue'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('rues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clue'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('clues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('happyness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stupid'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('stupidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cruelti'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowstemmer.stem('cruelty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queu'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('queues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appl'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cue'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('cues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rue'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('rues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clu'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('clues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dumbl'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('dumbles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('sadness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadddd'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('sadddddness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('saddness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saddd'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('saddddness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('computing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stapl'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('stapler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cwjwcber'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('cwjwcber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ub'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('uber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oob'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('oober')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "stemmer = RegexpStemmer('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appl'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xsjbkdcw'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('xsjbkdcwes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cwjwcb'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('cwjwcbes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cwjwcber'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('cwjwcber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'greatness',\n",
       " 'of',\n",
       " 'kaichou',\n",
       " 'wa',\n",
       " 'maid',\n",
       " 'sama',\n",
       " '>',\n",
       " '.',\n",
       " '<',\n",
       " '<3',\n",
       " ':D',\n",
       " '#awesome',\n",
       " '@user32']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "text = 'The greatness of kaichou wa maid sama >.< <3 :D #awesome @user32'\n",
    "twtkn = TweetTokenizer()\n",
    "twtkn.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('read', 'VBP'), ('the', 'DT'), ('newspaper', 'NN'), ('with', 'IN'), ('him', 'PRP'), ('.', '.')]\n",
      "[('We', 'PRP'), ('read', 'VBP'), ('three', 'CD'), ('pages', 'NNS'), ('back', 'RB'), ('to', 'TO'), ('back', 'VB'), ('.', '.')]\n",
      "[('Brat', 'NNP'), ('came', 'VBD'), ('for', 'IN'), ('the', 'DT'), ('breakfast', 'NN'), ('too', 'RB'), ('late', 'RB'), ('.', '.')]\n",
      "[('He', 'PRP'), ('has', 'VBZ'), ('his', 'PRP$'), ('own', 'JJ'), ('pace', 'NN'), ('of', 'IN'), ('doing', 'VBG'), ('things', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "texts = \"I read the newspaper with him. We read three pages back to back. Brat came for the breakfast too late. He has his own pace of doing things.\"\n",
    "sent_text=nltk.sent_tokenize(texts)\n",
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "example = \"The cat was chasing the mice\"\n",
    "example = [lemmatizer.lemmatize(token) for token in example.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat wa chasing the mouse\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "better\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better', pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 0 0]]\n",
      "[[1 1 1 1 1 1 0 1]\n",
      " [1 0 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(binary=True)\n",
    "corpus=[\"Tessaract is a good optical character recognition engine\", \"Optical character recognition is significant \"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform([\"Today is good optical\"]).toarray())\n",
    "print(vect.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character:0\n",
      "engine:1\n",
      "good:2\n",
      "is:3\n",
      "optical:4\n",
      "recognition:5\n",
      "significant:6\n",
      "tessaract:7\n"
     ]
    }
   ],
   "source": [
    "vocab=vect.vocabulary_\n",
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key, vocab[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:- Vectorizer and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "  (0, 16)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 42)\t1\n",
      "  (0, 56)\t1\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer(binary = True)\n",
    "corpus = [\"In a country like India, where a mass of population lives in the villages\", \"there are times when parents have work to take care of and cannot keep an eye on their children all day round\", \"In many cases, when even the females in houses have to go to work, but cannot always carry their children along with them\", \"they have no other choice but to leave them back at their homes. Due to these reasons and more, there has been a rapid increase in security risks of children recently\"]\n",
    "vector.fit(corpus)\n",
    "print(vector.transform([\"country population mass times parents parents parents hello\"]).toarray())\n",
    "print(vector.transform([\"country population mass times parents parents parents hello\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "  (0, 16)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 41)\t3\n",
      "  (0, 42)\t1\n",
      "  (0, 56)\t1\n"
     ]
    }
   ],
   "source": [
    "vector = CountVectorizer(binary = False)\n",
    "corpus = [\"In a country like India, where a mass of population lives in the villages\", \"there are times when parents have work to take care of and cannot keep an eye on their children all day round\", \"In many cases, when even the females in houses have to go to work, but cannot always carry their children along with them\", \"they have no other choice but to leave them back at their homes. Due to these reasons and more, there has been a rapid increase in security risks of children recently\"]\n",
    "vector.fit(corpus)\n",
    "v1 = vector.transform([\"country population mass times parents parents parents hello\"]).toarray()\n",
    "print(v1)\n",
    "v2 = vector.transform([\"hello world country population so scared\"]).toarray()\n",
    "print(vector.transform([\"country population mass times parents parents parents hello\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39223227]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task:- Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "def last_letter(word):\n",
    "    return {'last_letter':word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 't'}, 'male'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 'a'}, 'female'),\n",
       " ({'last_letter': 'e'}, 'female'),\n",
       " ({'last_letter': 't'}, 'female'),\n",
       " ({'last_letter': 'y'}, 'female'),\n",
       " ({'last_letter': 'h'}, 'female'),\n",
       " ({'last_letter': 'n'}, 'female')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets=[(last_letter(n), gender) for (n, gender) in labeled_names]\n",
    "featuresets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "classifier.classify(last_letter('James'))\n",
    "classifier.classify(last_letter('Jessie'))\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
